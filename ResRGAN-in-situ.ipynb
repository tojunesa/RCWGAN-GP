{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, Add\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import identity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# Define hyperparameters\n",
    "gp_coef = 1\n",
    "latent_dim = 100\n",
    "lr_d = 1e-4\n",
    "lr_g = 2e-5\n",
    "optimizer_d = Adam(lr = lr_d, beta_1 = 0, beta_2 = 0.9)\n",
    "optimizer_g = Adam(lr = lr_g, beta_1 = 0, beta_2 = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock_G(X, filter_num):\n",
    "    #Residule block for the generator\n",
    "    X_copy = identity(X)\n",
    "    \n",
    "    X = Conv2D(filter_num, kernel_size = 3, strides = 1, padding = 'same')(X)\n",
    "    X = LeakyReLU(alpha = 0.2)(X)\n",
    "    X = Conv2D(filter_num, kernel_size = 3, strides = 1, padding = 'same')(X)\n",
    "        \n",
    "    X = Add()([X, X_copy])\n",
    "    X = LeakyReLU(alpha = 0.2)(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock_D(X, filter_num):\n",
    "    #Residule block for the discriminator\n",
    "    X_copy = identity(X)\n",
    "    \n",
    "    X = Conv2D(filter_num, kernel_size = 3, strides = 1, padding = 'same')(X)\n",
    "    X = LeakyReLU(alpha = 0.2)(X)\n",
    "    X = Conv2D(filter_num, kernel_size = 3, strides = 1, padding = 'same')(X)\n",
    "    \n",
    "    X = Add()([X, X_copy])\n",
    "    X = LeakyReLU(alpha = 0.2)(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    #Generator structure\n",
    "    noise = Input(shape = (latent_dim,))\n",
    "    in_label = Input(shape = (1,))\n",
    "    \n",
    "    gg = Dense(100*8*8)(noise)\n",
    "    gg = Reshape((8,8,100))(gg)\n",
    "    ll = Dense(8*8*16)(in_label)\n",
    "    ll = Reshape((8,8,16))(ll)\n",
    "    merge = Concatenate()([gg,ll])\n",
    "    \n",
    "    gen = Conv2DTranspose(64, kernel_size = 9, strides = 4, padding = 'same')(merge)\n",
    "    \n",
    "    gen = ResBlock_G(gen, 64)\n",
    "    gen = ResBlock_G(gen, 64)\n",
    "    gen = ResBlock_G(gen, 64)\n",
    "    gen = ResBlock_G(gen, 64)\n",
    "    gen = ResBlock_G(gen, 64)\n",
    "    gen = ResBlock_G(gen, 64)\n",
    "    \n",
    "    gen = Conv2D(256, kernel_size = 3, strides = 1, padding = 'same')(gen)\n",
    "    gen = UpSampling2D((2,2), interpolation='nearest')(gen)\n",
    "    gen = Conv2D(256, kernel_size = 3, strides = 1, padding = 'same')(gen)\n",
    "    gen = UpSampling2D((2,2), interpolation='nearest')(gen)\n",
    "    \n",
    "    gen = Conv2DTranspose(128, kernel_size = 7, strides = 2, padding = 'same')(gen)\n",
    "    gen = LeakyReLU(alpha = 0.2)(gen)\n",
    "    \n",
    "    out_layer = Conv2D(1, kernel_size = 11, strides = 1, activation = 'tanh', padding = 'same')(gen)\n",
    "    \n",
    "    \n",
    "    return Model([noise,in_label], out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    #discriminator structure\n",
    "    in_img = Input(shape = img_shape)\n",
    "    in_label = Input(shape = (1,))\n",
    "    \n",
    "    fe = Conv2D(64, kernel_size=4, strides=2, padding=\"same\")(in_img)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    \n",
    "    ll = Dense(64*64*20)(in_label)\n",
    "    ll = Reshape((64,64,20))(ll)\n",
    "    merge = Concatenate()([fe, ll])\n",
    "    \n",
    "    fe = Conv2D(256, kernel_size=4, strides=2, padding=\"same\")(merge)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)   \n",
    "    fe = Conv2D(512, kernel_size=5, strides=2, padding=\"same\")(merge)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe) \n",
    "\n",
    "    fe = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(128, kernel_size=3, strides=1, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(64, kernel_size=3, strides=1, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = ResBlock_D(fe, 64)\n",
    "    fe = Flatten()(fe)\n",
    "    fe = Dense(512)(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    \n",
    "    out_layer = Dense(1)(fe)\n",
    "    \n",
    "    return Model([in_img, in_label], out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g = generator()\n",
    "net_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_d = discriminator()\n",
    "net_d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_training(real_img, noise, label):\n",
    "    #One discriminator training step with gradient penalty\n",
    "    with tf.GradientTape() as tape_d:\n",
    "        fake_img = net_g([noise, label])\n",
    "        loss_real = tf.reduce_mean(net_d([real_img, label]))\n",
    "        loss_fake = tf.reduce_mean(net_d([fake_img, label]))\n",
    "        \n",
    "        #Calculate gradient penalty\n",
    "        with tf.GradientTape() as tape_penalty:\n",
    "            epsilon = tf.random.uniform([batch_size], 0, 1)\n",
    "            epsilon = tf.reshape(epsilon, (-1,1,1,1))\n",
    "            interpolated_img = epsilon*real_img + (1-epsilon)*fake_img\n",
    "            tape_penalty.watch(interpolated_img)\n",
    "            interpolated_out = net_d([interpolated_img, label])\n",
    "            grad_interpolated = tape_penalty.gradient(interpolated_out, interpolated_img)\n",
    "            grad_norm = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(grad_interpolated), axis = [1,2,3]))\n",
    "            grad_penalty = tf.reduce_mean(tf.math.square(grad_norm-1))\n",
    "        \n",
    "        loss = loss_fake - loss_real + gp_coef*grad_penalty\n",
    "        grad_d = tape_d.gradient(loss, net_d.trainable_weights)\n",
    "        optimizer_d.apply_gradients(zip(grad_d, net_d.trainable_weights))\n",
    "    \n",
    "    return (loss_real, loss_fake, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_training(noise, label):\n",
    "    #One generator training step with gradient penalty\n",
    "    with tf.GradientTape() as tape_g:\n",
    "        gen_img = net_g([noise, label])\n",
    "        loss = -tf.reduce_mean(net_d([gen_img, label]))\n",
    "        grad_g = tape_g.gradient(loss, net_g.trainable_weights)\n",
    "        optimizer_g.apply_gradients(zip(grad_g, net_g.trainable_weights))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples_and_rotate():\n",
    "    #load data and apply rotation to quadruple the train set size\n",
    "    dirct_name = 'training data/'\n",
    "    train_set = []\n",
    "    for i in range(8):\n",
    "        if i!=5:\n",
    "            #leave a subset as the validation set\n",
    "            for j in range(1,6):\n",
    "                subset_name = dirct_name + str(i) + '-' +str(j)\n",
    "                image_names = os.listdir(subset_name)\n",
    "                if '.ipynb_checkpoints' in image_names:\n",
    "                    image_names.remove('.ipynb_checkpoints')\n",
    "                for item in image_names:\n",
    "                    img = PIL.Image.open(subset_name+'/'+item)\n",
    "                    img_90 = img.transpose(PIL.Image.ROTATE_90)\n",
    "                    img_180 = img.transpose(PIL.Image.ROTATE_180)\n",
    "                    img_270 = img.transpose(PIL.Image.ROTATE_270)\n",
    "                    arr = np.asarray(img)\n",
    "                    arr_90 = np.asarray(img_90)\n",
    "                    arr_180 = np.asarray(img_180)\n",
    "                    arr_270 = np.asarray(img_270)\n",
    "                    train_set.append(arr)\n",
    "                    train_set.append(arr_90)\n",
    "                    train_set.append(arr_180)\n",
    "                    train_set.append(arr_270)\n",
    "            \n",
    "    train_X = np.reshape(train_set, (1080*6,256,256,1))\n",
    "    \n",
    "    labels = [0.73, 0.72, 0.7, 0.67, 0.66, 0.62, 0.56, 0.51]\n",
    "    \n",
    "    train_Y_l = []\n",
    "    for i in range(8):\n",
    "        if i != 5:\n",
    "            #leave a subset as the validation set (0.62)\n",
    "            train_Y_l.append(labels[i]*np.ones((1080,1)))\n",
    "\n",
    "    train_Y = np.reshape(train_Y_l, (-1,1))\n",
    "        \n",
    "    return (train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6480, 256, 256, 1)\n",
      "(6480, 1)\n"
     ]
    }
   ],
   "source": [
    "#load data and normalize them\n",
    "(train_X,train_Y) = load_samples_and_rotate()\n",
    "train_X_n = (train_X.astype(np.float32) - 127.5) / 127.5\n",
    "print(train_X_n.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss : -2617.074463] [G loss: -213.648804]\n",
      "5 [D loss : -853.758057] [G loss: 138.943497]\n",
      "10 [D loss : -509.043457] [G loss: 170.820892]\n",
      "15 [D loss : -334.369507] [G loss: 1113.373413]\n",
      "20 [D loss : -274.868958] [G loss: 1755.954590]\n",
      "25 [D loss : -269.553650] [G loss: 1157.455078]\n",
      "30 [D loss : -223.239746] [G loss: 1391.271729]\n",
      "35 [D loss : -209.037766] [G loss: 984.831604]\n",
      "40 [D loss : -210.923904] [G loss: 1015.291443]\n",
      "45 [D loss : -157.022949] [G loss: 887.205933]\n",
      "50 [D loss : -148.411987] [G loss: 1125.600586]\n",
      "55 [D loss : -163.724930] [G loss: 806.031921]\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "num_sample = train_X_n.shape[0]\n",
    "batch_size = 128\n",
    "num_minibatch = num_sample // batch_size\n",
    "\n",
    "for i in range(epochs):\n",
    "    shuffled_idx = np.random.randint(0, train_X_n.shape[0], train_X_n.shape[0])\n",
    "    for j in range(num_minibatch):\n",
    "        minibatch_idx = shuffled_idx[j*batch_size:(j+1)*batch_size]\n",
    "        imgs = train_X_n[minibatch_idx]\n",
    "        labels = train_Y[minibatch_idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        err_d_real, err_d_fake, loss_total = d_training(imgs, noise, labels)\n",
    "        err_g = g_training(noise, labels)\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        print (\"epoch number: %d\" % (i))\n",
    "        r = 2\n",
    "        c = 2\n",
    "        noise_g = np.random.normal(0, 1, (1, 100))\n",
    "        for m in range(2):\n",
    "            noise_c = np.copy(noise_g)\n",
    "            noise_g = np.concatenate((noise_g, noise_c), axis = 0)\n",
    "        sampled_labels = np.asarray(([0.72,0.7,0.62,0.51]))\n",
    "        fake_imgs = net_g.predict([noise_g, sampled_labels])\n",
    "        fake_imgs = fake_imgs * 127.5 + 127.5\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for k in range(r):\n",
    "            for l in range(c):\n",
    "                axs[k,l].imshow(fake_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[k,l].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"saved_images/%d.png\" % i)\n",
    "        plt.close()\n",
    "        \n",
    "net_g.save('generator_0209')\n",
    "net_d.save('discriminator_0209')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
