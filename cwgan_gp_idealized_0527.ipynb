{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, Concatenate, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "\n",
    "lr_d = 2e-5\n",
    "lr_g = 5e-6\n",
    "optimizer_d = Adam(lr = lr_d, beta_1 = 0.0, beta_2 = 0.9)\n",
    "optimizer_g = Adam(lr = lr_g, beta_1 = 0.0, beta_2 = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic():\n",
    "    in_img = Input(shape = img_shape)\n",
    "    in_label = Input(shape = (1,))\n",
    "    ll = Dense(256*256)(in_label)\n",
    "    ll = Reshape(img_shape)(ll)\n",
    "    merge = Concatenate()([in_img, ll])\n",
    "    \n",
    "    fe = Conv2D(8, kernel_size=5, strides=2, padding=\"same\")(merge)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(16, kernel_size=5, strides=2, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(32, kernel_size=5, strides=2, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(64, kernel_size=5, strides=2, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(128, kernel_size=5, strides=2, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(256, kernel_size=5, strides=2, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Conv2D(512, kernel_size=5, strides=2, padding=\"same\")(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    fe = Flatten()(fe)\n",
    "    fe = Dense(512)(fe)\n",
    "    fe = LeakyReLU(alpha = 0.2)(fe)\n",
    "    \n",
    "    out_layer = Dense(1, kernel_regularizer=regularizers.l2(0.1))(fe)\n",
    "    \n",
    "    return Model([in_img, in_label], out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    noise = Input(shape = (latent_dim,))\n",
    "    in_label = Input(shape = (1,))\n",
    "    \n",
    "    gg = Dense(128*8*8)(noise)\n",
    "    gg = Reshape((8,8,128))(gg)\n",
    "    ll = Dense(8*8*16)(in_label)\n",
    "    ll = Reshape((8,8,16))(ll)\n",
    "    merge = Concatenate()([gg,ll])\n",
    "    \n",
    "    gen = Conv2DTranspose(128, kernel_size = 5, strides = 2, padding = 'same')(merge)\n",
    "    gen = LeakyReLU(alpha = 0.2)(gen)\n",
    "    gen = Conv2DTranspose(64, kernel_size = 5, strides = 2, padding = 'same')(gen)\n",
    "    gen = LeakyReLU(alpha = 0.2)(gen)\n",
    "    gen = Conv2DTranspose(32, kernel_size = 5, strides = 2, padding = 'same')(gen)\n",
    "    gen = LeakyReLU(alpha = 0.2)(gen)\n",
    "    gen = Conv2DTranspose(16, kernel_size = 5, strides = 2, padding = 'same')(gen)\n",
    "    gen = LeakyReLU(alpha = 0.2)(gen)\n",
    "    gen = Conv2DTranspose(8, kernel_size = 5, strides = 2, padding = 'same')(gen)\n",
    "    gen = LeakyReLU(alpha = 0.2)(gen)\n",
    "\n",
    "    \n",
    "    gen = Conv2D(8, kernel_size =3, activation = 'tanh', padding = 'same')(gen)\n",
    "    out_layer = Conv2D(1, kernel_size = 3, activation = 'tanh', padding = 'same')(gen)\n",
    "    \n",
    "    \n",
    "    return Model([noise,in_label], out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 65536)        131072      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 256, 256, 1)  0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 256, 2)  0           input_1[0][0]                    \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 8)  408         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 128, 128, 8)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   3216        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 16)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   12832       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 64)   51264       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 128)    204928      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 8, 8, 128)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 4, 4, 256)    819456      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 4, 4, 256)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 2, 2, 512)    3277312     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 2, 2, 512)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            513         leaky_re_lu_7[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,550,089\n",
      "Trainable params: 5,550,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net_d = critic()\n",
    "net_d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8192)         827392      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         2048        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 8, 8, 128)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 8, 8, 16)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 144)    0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 128)  460928      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 128)  0           conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 64)   204864      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 32)   51232       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 16) 12816       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 128, 128, 16) 0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 8)  3208        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 256, 256, 8)  0           conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 8)  584         leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 1)  73          conv2d_7[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,563,145\n",
      "Trainable params: 1,563,145\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net_g = generator()\n",
    "net_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_training(real_img, noise, label):\n",
    "    with tf.GradientTape() as tape_d:\n",
    "        fake_img = net_g([noise, label])\n",
    "        loss_real = tf.reduce_mean(net_d([real_img, label]))\n",
    "        loss_fake = tf.reduce_mean(net_d([fake_img, label]))\n",
    "        \n",
    "        with tf.GradientTape() as tape_penalty:\n",
    "            epsilon = tf.random.uniform([batch_size], 0, 1)\n",
    "            epsilon = tf.reshape(epsilon, (-1,1,1,1))\n",
    "            interpolated_img = epsilon*real_img + (1-epsilon)*fake_img\n",
    "            tape_penalty.watch(interpolated_img)\n",
    "            interpolated_out = net_d([interpolated_img, label])\n",
    "            grad_interpolated = tape_penalty.gradient(interpolated_out, interpolated_img)\n",
    "            grad_norm = K.sqrt(K.sum(K.square(grad_interpolated), axis = [1,2,3]))\n",
    "            grad_penalty = K.mean(K.square(grad_norm-1))\n",
    "        \n",
    "        loss = loss_fake - loss_real + 1*grad_penalty\n",
    "        grad_d = tape_d.gradient(loss, net_d.trainable_weights)\n",
    "        optimizer_d.apply_gradients(zip(grad_d, net_d.trainable_weights))\n",
    "    \n",
    "    return (loss_real, loss_fake, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_training(noise, label):\n",
    "    with tf.GradientTape() as tape_g:\n",
    "        gen_img = net_g([noise, label])\n",
    "        loss = -tf.reduce_mean(net_d([gen_img, label]))\n",
    "        grad_g = tape_g.gradient(loss, net_g.trainable_weights)\n",
    "        optimizer_g.apply_gradients(zip(grad_g, net_g.trainable_weights))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples():\n",
    "    dirct_name = 'idealized micrographs/'\n",
    "    \n",
    "    train_set = []\n",
    "    for i in range(1,12):\n",
    "        subset_name = dirct_name + 'pdf' + str(i)\n",
    "        image_names = os.listdir(subset_name)\n",
    "        if '.ipynb_checkpoints' in image_names:\n",
    "            image_names.remove('.ipynb_checkpoints')\n",
    "        for item in image_names:\n",
    "            img = PIL.Image.open(subset_name+'/'+item)\n",
    "            arr = np.asarray(img)   \n",
    "            train_set.append(arr)\n",
    "                \n",
    "            \n",
    "    train_X = np.reshape(train_set, (3000*11,256,256,1))\n",
    "    \n",
    "    labels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1]\n",
    "    \n",
    "    train_Y_l = []\n",
    "    for i in range(11):\n",
    "        train_Y_l.append(labels[i]*np.ones((3000,1)))\n",
    "        \n",
    "\n",
    "    train_Y = np.reshape(train_Y_l, (-1,1))\n",
    "        \n",
    "    return (train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 256, 256, 1)\n",
      "(33000, 1)\n"
     ]
    }
   ],
   "source": [
    "(train_X,train_Y) = load_samples()\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_n = (train_X.astype(np.float32) - 0.5) / 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 256, 256, 1)\n",
      "(30000, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "#train and test set split\n",
    "test_X = train_X_n[5*3000:6*3000]\n",
    "train_X_split = np.concatenate((train_X_n[0:5*3000], train_X_n[6*3000:]))\n",
    "test_Y = train_Y[5*3000:6*3000]\n",
    "train_Y_split = np.concatenate((train_Y[0:5*3000], train_Y[6*3000:]))\n",
    "\n",
    "print(test_X.shape)\n",
    "print(train_X_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[ True]\n",
      "[1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_X_split[1],'gray')\n",
    "print(train_X_split[1][20][18])\n",
    "print(train_X[1][20][18])\n",
    "print(train_X[1][20][18].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss : 0.993965] [G loss: 0.000080]\n",
      "200 [D loss : -9439.722656] [G loss: -55.513046]\n",
      "400 [D loss : -12138.750000] [G loss: -492.372986]\n",
      "600 [D loss : -10977.472656] [G loss: -2536.614746]\n",
      "800 [D loss : -7320.912109] [G loss: -4960.238770]\n",
      "1000 [D loss : -4167.177734] [G loss: -3955.082275]\n",
      "1200 [D loss : -2941.420410] [G loss: 1740.855713]\n",
      "1400 [D loss : -3777.000000] [G loss: 1447.374023]\n",
      "1600 [D loss : -3726.622314] [G loss: 1935.254028]\n",
      "1800 [D loss : -3544.000244] [G loss: 464.967072]\n",
      "2000 [D loss : -2949.681885] [G loss: -1547.033936]\n",
      "2200 [D loss : -2165.202393] [G loss: -2741.701904]\n",
      "2400 [D loss : -1763.595947] [G loss: -3240.333984]\n",
      "2600 [D loss : -2424.676025] [G loss: -2606.427002]\n",
      "2800 [D loss : -2569.311523] [G loss: -1752.738037]\n",
      "3000 [D loss : -2688.349121] [G loss: -1119.095459]\n",
      "3200 [D loss : -3251.802246] [G loss: -940.910400]\n",
      "3400 [D loss : -2967.203125] [G loss: -555.157837]\n",
      "3600 [D loss : -2763.044434] [G loss: -608.205383]\n",
      "3800 [D loss : -2582.634521] [G loss: -700.006714]\n",
      "4000 [D loss : -2581.236328] [G loss: -932.296875]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-00d33e264557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_Y_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0merr_d_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_d_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0merr_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6d8a67ca508d>\u001b[0m in \u001b[0;36md_training\u001b[0;34m(real_img, noise, label)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0minterpolated_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreal_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfake_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtape_penalty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolated_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0minterpolated_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolated_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_gpu_env/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m           y = ops.convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m    988\u001b[0m               y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_gpu_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m   \"\"\"\n\u001b[0;32m-> 1278\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1279\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_gpu_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m         ret = conversion_func(\n\u001b[0m\u001b[1;32m   1329\u001b[0m             value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_gpu_env/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_gpu_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[0;32m--> 261\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    262\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_gpu_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/keras_gpu_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "num_sample = train_X_split.shape[0]\n",
    "batch_size = 128\n",
    "num_minibatch = num_sample // batch_size + 1\n",
    "g_loss_history = []\n",
    "\n",
    "    \n",
    "for i in range(epochs):\n",
    "    shuffled_idx = np.random.randint(0, train_X_split.shape[0],train_X_split.shape[0])\n",
    "    for j in range(num_minibatch):\n",
    "        minibatch_idx = shuffled_idx[j*batch_size:min((j+1)*batch_size, num_sample)]\n",
    "        imgs = train_X_split[idx]\n",
    "        labels = train_Y_split[idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        err_d_real, err_d_fake, loss_total = d_training(imgs, noise, labels)\n",
    "        err_g = g_training(noise, labels)\n",
    "\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print (\"%d [D loss : %f] [G loss: %f]\" % (i, loss_total, err_g))\n",
    "        g_loss_history.append(err_g)\n",
    "        r = 2\n",
    "        c = 2\n",
    "        noise_g = np.random.normal(0, 1, (1, 100))\n",
    "        for j in range(2):\n",
    "            noise_c = np.copy(noise_g)\n",
    "            noise_g = np.concatenate((noise_g, noise_c), axis = 0)\n",
    "        sampled_labels = np.asarray(([0.1,0.4,0.8,1.1]))\n",
    "        fake_imgs = net_g.predict([noise_g, sampled_labels])\n",
    "        fake_imgs = fake_imgs * 0.5 + 0.5\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for k in range(r):\n",
    "            for l in range(c):\n",
    "                axs[j,k].imshow(fake_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[j,k].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"saved_images/%d.png\" % i)\n",
    "        plt.close()\n",
    "        \n",
    "net_g.save('saved_models/idealized_generator_0527')\n",
    "net_d.save('saved_models/idealized_discriminator_0527')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "los_hist = np.asarray(g_loss_history)\n",
    "los_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KerasGPU",
   "language": "python",
   "name": "keras_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
